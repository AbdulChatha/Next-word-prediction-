{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Link:https://www.kaggle.com/datasets/sankha1998/emotion"
      ],
      "metadata": {
        "id": "e9KMJdnQghk-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "593k7bCPX-mu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdfca3dc-41c0-4334-b847-b9993c5ed87a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "angry_df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/WhatsApp/Emotion(angry).csv')\n",
        "happy_df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/WhatsApp/Emotion(happy).csv')\n",
        "sad_df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/WhatsApp/Emotion(sad).csv')\n",
        "combined_df=pd.concat([angry_df,happy_df,sad_df],axis=0)"
      ],
      "metadata": {
        "id": "n-_w5OZvsU4X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_df=combined_df['content']\n",
        "content_df=content_df.sample(600)"
      ],
      "metadata": {
        "id": "mSFUjdqUtF-h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2uEf_bo8Mij",
        "outputId": "3aca5fbf-f5d4-427d-c39b-a2b62e7325e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "444        My heart is perfect because.. you are inside.\n",
              "269          I Am Who I Am. Your Approval Is Not Needed.\n",
              "282    There’s always a person that you hate for no r...\n",
              "660    Love begins with a smile, grows with a kiss, a...\n",
              "343    To be happy does not mean that all is perfect....\n",
              "                             ...                        \n",
              "516                     love me less but love me long...\n",
              "612    We’re the Perfect Couple, We’re just not in th...\n",
              "62     You left without a reason, so please don't com...\n",
              "45     There are 3 types of people in the world- vege...\n",
              "534    ['You Hurt Me But I Still Love You.', 'True Lo...\n",
              "Name: content, Length: 600, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "RcBpQnKRKqnV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()"
      ],
      "metadata": {
        "id": "KhWMGqepK_0P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(content_df)"
      ],
      "metadata": {
        "id": "d7zBkhazLE5Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(tokenizer.word_index)"
      ],
      "metadata": {
        "id": "gDo1LBcULSS0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences(content_df)[0:7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-Dy7xjTLy6K",
        "outputId": "3fa0f6e6-e244-450f-dc07-798281f40a1d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[27, 51, 6, 263, 31, 2, 22, 100],\n",
              " [5, 70, 32, 5, 70, 16, 953, 6, 24, 906],\n",
              " [441, 54, 7, 55, 10, 2, 137, 8, 149, 91],\n",
              " [48, 1109, 49, 7, 71, 1110, 49, 7, 907, 20, 278, 49, 7, 1111],\n",
              " [3,\n",
              "  18,\n",
              "  107,\n",
              "  868,\n",
              "  24,\n",
              "  130,\n",
              "  10,\n",
              "  109,\n",
              "  6,\n",
              "  263,\n",
              "  12,\n",
              "  271,\n",
              "  10,\n",
              "  2,\n",
              "  41,\n",
              "  954,\n",
              "  3,\n",
              "  221,\n",
              "  472,\n",
              "  873,\n",
              "  1112],\n",
              " [1113,\n",
              "  5,\n",
              "  442,\n",
              "  41,\n",
              "  74,\n",
              "  3,\n",
              "  137,\n",
              "  28,\n",
              "  32,\n",
              "  137,\n",
              "  13,\n",
              "  1114,\n",
              "  874,\n",
              "  35,\n",
              "  443,\n",
              "  416,\n",
              "  28,\n",
              "  32,\n",
              "  48,\n",
              "  13],\n",
              " [172,\n",
              "  406,\n",
              "  5,\n",
              "  908,\n",
              "  147,\n",
              "  428,\n",
              "  61,\n",
              "  2,\n",
              "  20,\n",
              "  144,\n",
              "  406,\n",
              "  5,\n",
              "  909,\n",
              "  128,\n",
              "  5,\n",
              "  70,\n",
              "  1115,\n",
              "  27,\n",
              "  74]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences=[]\n",
        "for sentence in content_df:\n",
        "  tokenized_sentence=tokenizer.texts_to_sequences([sentence])[0]\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[0:i+1])"
      ],
      "metadata": {
        "id": "ER83tsTlMHFp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences[0:14]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKwt-ghrNORP",
        "outputId": "46e56e30-56c1-404e-b02c-8da3078dafe5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[27, 51],\n",
              " [27, 51, 6],\n",
              " [27, 51, 6, 263],\n",
              " [27, 51, 6, 263, 31],\n",
              " [27, 51, 6, 263, 31, 2],\n",
              " [27, 51, 6, 263, 31, 2, 22],\n",
              " [27, 51, 6, 263, 31, 2, 22, 100],\n",
              " [5, 70],\n",
              " [5, 70, 32],\n",
              " [5, 70, 32, 5],\n",
              " [5, 70, 32, 5, 70],\n",
              " [5, 70, 32, 5, 70, 16],\n",
              " [5, 70, 32, 5, 70, 16, 953],\n",
              " [5, 70, 32, 5, 70, 16, 953, 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=max([len(x) for x in input_sequences])\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ2BBjw_NbsY",
        "outputId": "a2b7fa86-9e35-4f1d-e1d5-9d3176da97fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2272"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences=pad_sequences(input_sequences,maxlen=max_len,padding='pre')\n",
        "padded_input_sequences[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ4fbBLxNyCq",
        "outputId": "528e2be6-cd1b-4b52-b9f4-72d64b61bc9f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  27,  51],\n",
              "       [  0,   0,   0, ...,  27,  51,   6],\n",
              "       [  0,   0,   0, ...,  51,   6, 263],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0,   5,  70],\n",
              "       [  0,   0,   0, ...,   5,  70,  32],\n",
              "       [  0,   0,   0, ...,  70,  32,   5]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=padded_input_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "I0JTBdylOWkX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "xAl6t5C5Of-T"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encoding\n",
        "num_classes=len(tokenizer.word_index)+1#num classes mean number of unique words in document\n",
        "# num_classes  #282\n",
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=num_classes)"
      ],
      "metadata": {
        "id": "StTYOhzcO50A"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "2E2zjRfmP9-3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding"
      ],
      "metadata": {
        "id": "INjaWxtpfqOJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(num_classes,100,input_length=max_len-1))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(num_classes,activation='softmax'))"
      ],
      "metadata": {
        "id": "0qVJ7GGWf58m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vk1OOifjg6qk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc20lldehLPq",
        "outputId": "39b1f085-fc48-48cd-b836-fdeecb6c192c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 2271, 100)         174700    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 150)               150600    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1747)              263797    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 589097 (2.25 MB)\n",
            "Trainable params: 589097 (2.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=5,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF0D_XOjhN4m",
        "outputId": "0262b40d-7ad2-44a9-a876-79381f518c0b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3843/3843 [==============================] - 374s 95ms/step - loss: 4.1370 - accuracy: 0.2300 - val_loss: 2.2059 - val_accuracy: 0.5420\n",
            "Epoch 2/5\n",
            "3843/3843 [==============================] - 361s 94ms/step - loss: 1.2448 - accuracy: 0.7726 - val_loss: 0.5912 - val_accuracy: 0.9236\n",
            "Epoch 3/5\n",
            "3843/3843 [==============================] - 356s 93ms/step - loss: 0.4231 - accuracy: 0.9425 - val_loss: 0.2801 - val_accuracy: 0.9554\n",
            "Epoch 4/5\n",
            "3843/3843 [==============================] - 355s 92ms/step - loss: 0.2617 - accuracy: 0.9546 - val_loss: 0.1947 - val_accuracy: 0.9621\n",
            "Epoch 5/5\n",
            "3843/3843 [==============================] - 357s 93ms/step - loss: 0.1998 - accuracy: 0.9598 - val_loss: 0.1545 - val_accuracy: 0.9691\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a35cf575150>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "text = \" There are 3 types\"\n",
        "\n",
        "for i in range(15):\n",
        "  token_text=tokenizer.texts_to_sequences([text])[0]\n",
        "  padded_token=pad_sequences([token_text],maxlen=2271,padding='pre')\n",
        "  pos=np.argmax(model.predict(padded_token))\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index==pos:\n",
        "      text=text+\" \"+word\n",
        "      print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gg7hhy4_9vg",
        "outputId": "c9b30d93-2437-40c1-d7a6-16a1f743a339"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n",
            " There are 3 types of\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            " There are 3 types of people\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            " There are 3 types of people in\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            " There are 3 types of people in your\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            " There are 3 types of people in your heart\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            " There are 3 types of people in your heart to\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            " There are 3 types of people in your heart to make\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            " There are 3 types of people in your heart to make your\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            " There are 3 types of people in your heart to make your mouth\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            " There are 3 types of people in your heart to make your mouth work\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            " There are 3 types of people in your heart to make your mouth work than\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            " There are 3 types of people in your heart to make your mouth work than faster\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            " There are 3 types of people in your heart to make your mouth work than faster your\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            " There are 3 types of people in your heart to make your mouth work than faster your mind\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            " There are 3 types of people in your heart to make your mouth work than faster your mind and\n"
          ]
        }
      ]
    }
  ]
}